<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[缓存穿透、缓存雪崩、hot key]]></title>
    <url>%2F2018%2F02%2F03%2F%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81hot-key%2F</url>
    <content type="text"><![CDATA[在做排行榜的时候，对缓存的更新频率产生了一定的疑问，在网上也看了不少博客对这方面的介绍，这里对看到的知识做个总结。 缓存穿透缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时要查询数据库，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞 解决方法1. 空值缓存这是一个比较简单暴力的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 缺点 空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间 ( 如果是攻击，问题更严重 )，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。 缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为 5 分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。 2. Bloom FilterBloom Filter是一个占用空间很小、效率很高的随机数据结构，它由一个bit数组和一组Hash算法构成。可用于判断一个元素是否在一个集合中，查询效率很高（1-N，最优能逼近于1）。在很多场景下，我们都需要一个能迅速判断一个元素是否在一个集合中。譬如： 网页爬虫对URL的去重，避免爬取相同的URL地址； 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信）； 缓存击穿，将已存在的缓存放到布隆中，当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉。 原理初始化状态是一个全为0的bit数组 为了表达存储N个元素的集合，使用K个独立的函数来进行哈希运算。x1，x2……xk为k个哈希算法。如果集合元素有N1，N2……NN，N1经过x1运算后得到的结果映射的位置标1，经过x2运算后结果映射也标1，已经为1的报错1不变。经过k次散列后，对N1的散列完成。依次对N2，NN等所有数据进行散列，最终得到一个部分为1，部分位为0的字节数组。当然了，这个字节数组会比较长，不然散列效果不好。 那么怎么判断一个外来的元素是否已经在集合里呢，譬如已经散列了10亿个垃圾邮箱，现在来了一个邮箱，怎么判断它是否在这10亿里面呢？很简单，就拿这个新来的也依次经历x1，x2……xk个哈希算法即可。在任何一个哈希算法譬如到x2时，得到的映射值有0，那就说明这个邮箱肯定不在这10亿内。如果是一个黑名单对象，那么可以肯定的是所有映射都为1，肯定跑不了它。也就是说是坏人，一定会被抓。那么误伤是为什么呢，就是指一些非黑名单对象的值经过k次哈希后，也全部为1，但它确实不是黑名单里的值，这种概率是存在的，但是是可控的。 至于具体实现，可以直接调用com.google.guava中的BloomFilter，就不赘述了。 缓存雪崩平时我们设定一个缓存的过期时间时，可能有一些会设置1分钟啊，5分钟这些，并发很高时可能会出在某一个时间同时生成了很多的缓存，并且过期时间都一样，这个时候就可能引发一当过期时间到后，这些缓存同时失效，请求全部转发到DB，DB可能会压力过重。 解决方法 将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。 热key重建开发人员使用缓存 + 过期时间的策略既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求。但是有两个问题如果同时出现，可能就会对应用造成致命的危害： 当前 key 是一个热点 key( 例如一个热门的娱乐新闻），并发量非常大。 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的 SQL、多次IO、多个依赖等。 在缓存失效的瞬间，有大量线程来重建缓存 ( 如下图)，造成后端负载加大，甚至可能会让应用崩溃。 要解决这个问题也不是很复杂，但是不能为了解决这个问题给系统带来更多的麻烦，所以需要制定如下目标： 减少重建缓存的次数 数据尽可能一致 较少的潜在危险 解决方案1. 互斥锁此方法只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。 这种方案思路比较简单，但是存在一定的隐患，如果构建缓存过程出现问题或者时间较长，可能会存在死锁和线程池阻塞的风险，但是这种方法能够较好的降低后端存储负载并在一致性上做的比较好。 2. 不设置超时时间“永远不过期”包含两层意思： 从缓存层面来看，确实没有设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。 从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存。 这种方案由于没有设置真正的过期时间，实际上已经不存在热点 key 产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。 http://mp.weixin.qq.com/s/TBCEwLVAXdsTszRVpXhVughttp://blog.csdn.net/tianyaleixiaowu/article/details/74721877http://blog.csdn.net/zeb_perfect/article/details/54135506https://zhuanlan.zhihu.com/p/26151305]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis排行榜]]></title>
    <url>%2F2018%2F02%2F03%2Fredis%E6%8E%92%E8%A1%8C%E6%A6%9C%2F</url>
    <content type="text"><![CDATA[设计思路因为看了一段时间的redis，准备动手做一个小demo，做一个排行榜，正好加在之前的未完成的新闻门户里面。关于排行榜他有一些跟排行榜本身相关的要求比如： 排行精确性如果一个排行榜的结果关系到用户的权益问题，这个时候一个排行榜的精确性就需要非常高，比如一个运营同学进行了根据微博转发数量的营销活动，这个时候微博转发数量的排行榜就需要非常精确，否则会影响用户权益的分发。 排行榜实时性游戏和社交互动的结合是目前的趋势，对于热门游戏的排行是用户的关注重点，在这部分用户中对于排行的实时性有很高的要求，如果一个用户升级了自己的装备和能力，而自己的排名一直没有更新，那这个用户一定要非常伤心抛弃这个游戏了。所以通过离线计算等平台来构建一个非实时的排行榜系统就不太适合这样的模型。 海量数据排行海量数据是目前的一个趋势，比如对于淘宝全网商品的一个排行，这个榜单将会是一个亿级别的，所以我们设计的榜单也需要具备弹性伸缩能力，同时在对海量数据进行排行的时候拥有一定的实时性。 实现方法目的是要实现一个热点新闻排行榜的话，毫无疑问，使用的是redis内置的zset这种数据结构，他可以根据score自动产生rank比较方便。我们将评论或者点赞数超过200的认为是热门文章 由于文章是从别的地方爬过来的，所以只有评论数没有点赞数，设置初始化分数为： score = 发布时间毫秒数 + 432 * 评论数 而问题就在排行榜更新的频率，更新过快，缓存效果不好，会产生类似重建热key的问题（下一篇文章要讲一下），但是频率过慢又不能达到实时性，所以正如之前所说的，要根据排行榜自身的要求制定一个适合的更新策略： 针对自身的这个项目需求，我想实现的是一个热点新闻排行榜，他的时效性要求并不是很高，所以通过分析网易新闻的爬取量，对爬到的每个新闻建立一个news：id进行初始化，并设置一周后过期自动删除，排行榜肯定是用zset的，但是为了不刷新过快，再建立一个zset缓存最近一个星期的文章，通过一个定时任务，每周一次定时维护time：，从time: 删除时间超过一个星期的文章，并重置score：，由于爬虫每隔6小时更新一次，且新闻量相对较小，所以对time：的频繁读写是可以容忍的。所以总的来说就是 爬取新闻，建立新的hash(news:id),设置过期时间为一周，并加入zset(time：) 每周执行一次更新，删除zset：中过期的任务，对未过期的任务分数进行更新。 score： zset news：id 分数 time： zset news：id 时间 news：id hash voted 投票数 title xxx url xxx 123456789101112131415161718192021@Servicepublic class Rank &#123; @Autowired private RedisDao redisDao; private final int ONE_WEEK_IN_SECONDS = 7 * 86400; public void updataRank() &#123; redisDao.zRemRangeByRang("time:", 0, -1); long cutOff = System.currentTimeMillis() / 1000 - ONE_WEEK_IN_SECONDS; Set&lt;TypedTuple&lt;Object&gt;&gt; set = redisDao.zRangeWithScores("time:", 0, -1); for (TypedTuple&lt;Object&gt; o: set) &#123; //如果过期直接删除，否则计算结果 if (Long.valueOf(o.getScore().toString()) &lt; cutOff) &#123; redisDao.zrem("time:", o.getValue()); &#125; else &#123; redisDao.zadd("score:", o.getValue(), Double.valueOf(o.getValue().toString()) + 432 * Double.valueOf(redisDao.hget(o.getValue().toString(), "commentCount").toString())); &#125; &#125; &#125;&#125; 完整代码请参考： https://github.com/MoriatyC/OmegaNews]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>缓存</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据安全与性能保障]]></title>
    <url>%2F2018%2F01%2F29%2Fredis%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BF%9D%E9%9A%9C%2F</url>
    <content type="text"><![CDATA[一.持久化1. 快照： 将存在于某一时刻的所有数据都写入硬盘里面方法： 客户端通过向redis发送bgsave命令（创建子进程） 客户端通过向redis发送save命令，但是会阻塞其他命令，所以只有内存不够，或者不怕阻塞的时候才可以用。但是不要创建子进程，不会导致redis停顿，并且由于没有子进程抢资源所以比bgsave快。 设置了save选项：比如 save 60 10000，表示从最近一次创建快照之后开始算起，当有60s内有10000次写入的时候就会触发bgsave命令，可以有多个save配置，任意一个满足即可。 通过shutdown接收到关闭请求时，或者接收到标准的term信号，执行save命令 当一个redis服务器连接另一个redis服务器，想对方发送sync时，若主服务器没执行bgsave，或者并非刚刚执行完，那么主服务器就会执行bgsave。 缺点：当redis、系统或者硬件中的一个发生崩溃，将丢失最近一次创建快照后的数据。TIPS: 将开发环境尽可能的模拟生产环境以得到正确的快照生成速率配置。 2. AOF：在执行写命令时，将被执行的写命令复制到硬盘里面使用appendonlyyes配置选项打开，下图是appendfsync配置选项。 选项目 同步频率 always 每个写操作都要同步写入，严重降低redis速度损耗硬盘寿命 everysec 每秒执行一次，将多个写入同步，墙裂推荐 no 让os决定，不稳定，不知道会丢失多少数据 自动配置aof重写： auto-aof-rewrite-percentage 100 auto-aof-rrewrite-min-size 64当启用aof持久化之后，当aof文件体积大于64mb并且体积比上一次大了100%，就会执行bgrewriteaof命令。 缺点：1.aof文件过大，2. 文件过大导致还原事件过长。但是可以对其进行重写压缩。 二. 复制就像之前所说当一个从服务器连接一个主服务器的时候，主服务器会创建一个快照文件并将其发送到从服务器。 在配置中包含slaveof host port选项指定主服务器，启动时候会先执行aof或者快照文件。 也可以通过发送flaveof no one命令来终止复制操作，通过slaveof host port命令来开始复制一个主服务器，会直接执行下面的连接操作。 步骤 主服务器操作 从服务器操作 1 （等待命令） 连接主服务器，发送sync命令 2 开始执行bgsave，并使用缓冲区记录bgsave之后执行的所有写命令 根据配置选项决定使用现有数据处理客户端请求还是返回错误 3 Bgsave执行完毕，向从服务器发快照，并在发送期间继续用缓冲区记录写命令 丢弃所有旧数据，载入快照文件 4 快照发送完毕，向从服务器发送缓冲区里的写命令 完成快照解释，开始接受命令 5 缓冲区存储的写命令发送完毕：从现在起每执行一个写命令都发给从服务器 执行主服务器发来的所有存储在缓冲区里的写；并接受执行主服务器发来的写命令 三. 处理故障系统验证快照和aof文件 redis-check-aof redis-check-dump 检查aof和快照文件的状态，在有需要的情况下对aof文件进行修复。 更换新的故障主服务器假设A为主服务器，B为从服务器，当机器A发生故障的时候，更换服务器的步骤如下：首先向机器B发送一个save命令，将这个快照文件发送给机器C，在C上启动Redis，让B成为C的从服务器。 将从服务器升级为主服务器将从服务器升级为主服务器，为升级后的主服务器创建从服务器。 redis事务四. 事务multi: 标记一个事务块的开始。 事务块内的多条命令会按照先后顺序被放进一个队列当中，最后由 EXEC 命令原子性(atomic)地执行。 exec: 执行所有事务块内的命令。 假如某个(或某些) key 正处于 WATCH 命令的监视之下，且事务块中有和这个(或这些) key 相关的命令，那么 EXEC 命令只在这个(或这些) key 没有被其他命令所改动的情况下执行并生效，否则该事务被打断(abort)。 redis的事务包裹在multi命令和exec命令之中，在jedis中通过如下实现12345678910111213141516171819202122232425262728293031323334 public class RedisJava extends Thread&#123; static Response&lt;String&gt; ret; Jedis conn = new Jedis("localhost"); @Override public void run() &#123; Transaction t = conn.multi(); t.incr("notrans:"); Response&lt;String&gt; result1 = t.get("notrans:"); try &#123; Thread.sleep(1L); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; t.incrBy("notrans:", -1); t.exec(); String foolbar = result1.get(); System.out.println(foolbar); &#125; public static void main(String[] args) &#123; Jedis conn = new Jedis("localhost"); Thread t1 = new RedisJava(); Thread t2 = new RedisJava(); Thread t3 = new RedisJava(); t1.start(); t2.start(); t3.start(); &#125;&#125; wathc：监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 unwatch：取消 WATCH 命令对所有 key 的监视。如果在执行 WATCH 命令之后， EXEC 命令或 DISCARD 命令先被执行了的话，那么就不需要再执行 UNWATCH 了。的监视，因此这两个命令执行之后，就没有必要执行 UNWATCH 了。 discard :取消事务，放弃执行事务块内的所有命令。取消watch，清空任务队列。如果正在使用 WATCH 命令监视某个(或某些) key，那么取消所有监视，等同于执行命令 UNWATCH 。 一个简单的商品买卖demo如下： key type inventory：id set market zset user:id hash 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public boolean listItem( Jedis conn, String itemId, String sellerId, double price) &#123; String inventory = "inventory:" + sellerId; String item = itemId + '.' + sellerId; long end = System.currentTimeMillis() + 5000; while (System.currentTimeMillis() &lt; end) &#123; conn.watch(inventory); if (!conn.sismember(inventory, itemId))&#123; conn.unwatch(); return false; &#125; Transaction trans = conn.multi(); trans.zadd("market:", price, item); trans.srem(inventory, itemId); List&lt;Object&gt; results = trans.exec(); // null response indicates that the transaction was aborted due to // the watched key changing. if (results == null)&#123; continue; &#125; return true; &#125; return false; &#125;public boolean purchaseItem( Jedis conn, String buyerId, String itemId, String sellerId, double lprice) &#123; String buyer = "users:" + buyerId; String seller = "users:" + sellerId; String item = itemId + '.' + sellerId; String inventory = "inventory:" + buyerId; long end = System.currentTimeMillis() + 10000; while (System.currentTimeMillis() &lt; end)&#123; conn.watch("market:", buyer); double price = conn.zscore("market:", item); double funds = Double.parseDouble(conn.hget(buyer, "funds")); if (price != lprice || price &gt; funds)&#123; conn.unwatch(); return false; &#125; Transaction trans = conn.multi(); trans.hincrBy(seller, "funds", (int)price); trans.hincrBy(buyer, "funds", (int)-price); trans.sadd(inventory, itemId); trans.zrem("market:", item); List&lt;Object&gt; results = trans.exec(); // null response indicates that the transaction was aborted due to // the watched key changing. if (results == null)&#123; continue; &#125; return true; &#125; 总结：相比于一般关系型数据库的悲观锁，redis的事务是典型的乐观锁，没有对事务进行封锁，以避免客户端运行过慢造成长时间的阻塞 非事务型流水线使用流水线，减少通信次数提高性能，以jedis为例，对比使用和没使用流水线的函数方法调用次数：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public void updateTokenPipeline(Jedis conn, String token, String user, String item) &#123; long timestamp = System.currentTimeMillis() / 1000; Pipeline pipe = conn.pipelined(); pipe.multi(); pipe.hset("login:", token, user); pipe.zadd("recent:", timestamp, token); if (item != null)&#123; pipe.zadd("viewed:" + token, timestamp, item); pipe.zremrangeByRank("viewed:" + token, 0, -26); pipe.zincrby("viewed:", -1, item); &#125; pipe.exec();&#125;//对比没有使用流水线的方法public void updateToken(Jedis conn, String token, String user, String item) &#123; long timestamp = System.currentTimeMillis() / 1000; conn.hset("login:", token, user); conn.zadd("recent:", timestamp, token); if (item != null) &#123; conn.zadd("viewed:" + token, timestamp, item); conn.zremrangeByRank("viewed:" + token, 0, -26); conn.zincrby("viewed:", -1, item); &#125;&#125;//测试函数如下 public void benchmarkUpdateToken(Jedis conn, int duration) &#123; try&#123; @SuppressWarnings("rawtypes") Class[] args = new Class[]&#123; Jedis.class, String.class, String.class, String.class&#125;; Method[] methods = new Method[]&#123; this.getClass().getDeclaredMethod("updateToken", args), this.getClass().getDeclaredMethod("updateTokenPipeline", args), &#125;; for (Method method : methods)&#123; int count = 0; long start = System.currentTimeMillis(); long end = start + (duration * 1000); while (System.currentTimeMillis() &lt; end)&#123; count++; method.invoke(this, conn, "token", "user", "item"); &#125; long delta = System.currentTimeMillis() - start; System.out.println( method.getName() + ' ' + count + ' ' + (delta / 1000) + ' ' + (count / (delta / 1000))); &#125; &#125;catch(Exception e)&#123; throw new RuntimeException(e); &#125;&#125; 运行结果如图所示，在本地运行性能提升大概17.8倍。 tips：可以使用redis-benchmark工具进行性能测试。 五. References 《Redis实战》]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>nosql</tag>
        <tag>持久化</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池(二)]]></title>
    <url>%2F2018%2F01%2F18%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[性能问题饥饿死锁如果线程池中的任务依赖于之后提交的子任务，当线程池不够大的时候，很容易造成饥饿死锁。所以最好在线程池中加入的是同类型的独立任务。 运行时间较长的任务如果线程运行时间较长也会影响任务的相应性，同样造成不好的体验，所以api有很多方法都带有一个限时版本。 线程池大小线程池的大小需要分析计算环境，资源预算和任务特性。 一般来说在知道了系统中有多少个cpu和内存的基础下，任务类型是最为重要的。 对于计算密集型的任务线程池大小为cpu数+1，以实现尽可能的满载利用率 对于i/o密集型，由于线程不会一直执行，所以规模更大。这里给出一个《Java并发变成实战》这本书提出的一个公式 最佳线程数目 = （线程等待时间/线程CPU时间之比 + 1） CPU数目cpu利用率 即等待时间越长，需要更多的线程。当我们不需要一个那么精准的线程数目时，也可以用这个公式 最佳线程数目 = 2N+1(N为CPU数目) 是否使用线程池就一定比使用单线程高效呢？答案是否定的，比如Redis就是单线程的，但它却非常高效，基本操作都能达到十万量级/s。从线程这个角度来看，部分原因在于： 多线程带来线程上下文切换开销，单线程就没有这种开销 锁 当然“Redis很快”更本质的原因在于：Redis基本都是内存操作，这种情况下单线程可以很高效地利用CPU。而多线程适用场景一般是：存在相当比例的IO和网络操作。 扩展线程池ThreadPoolExecutor提供了几个可以在子类化中该学的方法： beforeExecute afterExecute terminated 如果beforeExecute抛出一个RuntimeException，那么任务将不被执行，并且afterExecute也不会被调用。 但是无论人物从run中正常返回还是抛出一个异常返回，afterExecute都会被调用，如果任务在完成后带有一个Error，那么久不会调用。 所有任务都已经完成并且所有工作者线程也已经关闭后，terminated会被调用。 给出一个demo，他通过这一些列方法来统计任务执行并添加日志。123456789101112131415161718192021222324252627282930313233343536373839public class TimingThreadPool extends ThreadPoolExecutor &#123; public TimingThreadPool() &#123; super(1, 1, 0L, TimeUnit.SECONDS, null); &#125; private final ThreadLocal&lt;Long&gt; startTime = new ThreadLocal&lt;Long&gt;(); private final Logger log = Logger.getLogger("TimingThreadPool"); private final AtomicLong numTasks = new AtomicLong(); private final AtomicLong totalTime = new AtomicLong(); protected void beforeExecute(Thread t, Runnable r) &#123; super.beforeExecute(t, r); log.fine(String.format("Thread %s: start %s", t, r)); startTime.set(System.nanoTime()); &#125; protected void afterExecute(Runnable r, Throwable t) &#123; try &#123; long endTime = System.nanoTime(); long taskTime = endTime - startTime.get(); numTasks.incrementAndGet(); totalTime.addAndGet(taskTime); log.fine(String.format("Thread %s: end %s, time=%dns", t, r, taskTime)); &#125; finally &#123; super.afterExecute(r, t); &#125; &#125; protected void terminated() &#123; try &#123; log.info(String.format("Terminated: avg time=%dns", totalTime.get() / numTasks.get())); &#125; finally &#123; super.terminated(); &#125; &#125;&#125; 引用 http://ifeve.com/how-to-calculate-threadpool-size/《Java并发编程实战》]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池(一)]]></title>
    <url>%2F2018%2F01%2F17%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[概述这几天准备深入学习有关并发的知识，所以先简单复习了一下JDK自带的并发包，其中首先比较重要的一个就是线程池了。 为什么不无限的创造线程？主要基于以下几个原因： 线程生命周期的开销非常高 资源消耗 稳定性 所谓物极必反，线程的创建和销毁和需要一定的时间，如果所创建的线程工作时间还不如创建销毁的时间长那是得不偿失的，并且当线程创建过多也会对内存造成一定的负担甚至溢出，并且对GC也是极大的消耗，由于存在一定数额的活跃线程也提高了响应性。 线程池根据《阿里巴巴Java开发手册》中对线程创建的要求 【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程 由此可见，在正式生产环境中，线程池是唯一的创建线程的方法。而JDK对线程池也有强大的支持。 根据《手册》中的另一点要求 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明： Executors 返回的线程池对象的弊端如下：1） FixedThreadPool 和 SingleThreadPool:允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。2） CachedThreadPool 和 ScheduledThreadPool:允许的创建线程数量为 Integer.MAX_VALUE， 可能会创建大量的线程，从而导致 OOM 虽然Executor为我们提供了很多方便的工厂方法，比如newSingleThreadExecutor(),也有Executors为我们很好的实现了这些工厂方法，但是手动实现ThreadPoolExecutor能让我们对线程池有更深的了解和控制。所以接下来让我们来介绍一下ThreadPoolExecutor这个类。 原理一个最常见的ThreadPoolExecutor构造函数如下 1234567ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize： 活动线程数 maximumPoolSize： 线程池上限 keepAliveTime： 当线程池中线程数超过corePoolSize后，完成工作后的线程存活时间 unit： 单位其余的几个参数我们会在后面着重介绍。 这里介绍一下ThreadPoolExecutor的核心工作原理 123456789101112131415int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); workderCountOf()获得当前线程池线程总数，若小于corePoolSize，则直接将任务通过addWorker()方法执行，否则在workQueue.offer()进入等待队列，若进入失败，则任务直接交给线程池，若线程池达到了maximumPoolSize则提交失败执行拒绝策略 任务队列BlockingQueue：接口，阻塞队列，数据共享通道任务队列的作用在于，当线程池中线程数达到corePoolSize的时候，接下来的任务将进入这个队列进行等待，等待执行。 简单原理服务线程（获取队列信息并处理的线程）在队列为空时进行读等待，有新的消息进入队列后自动唤醒，反之，当队列满时进行写等待直到有消息出队。 不同于常用的offer()和poll()方法，这里我们使用take()和put()方法进行读写。我们以ArrayBlockingQueue的为例子,其中包括了这几个控制对象123final ReentrantLock lick;private final Condition notEmpty;private final Condition notFull; 就拿take()来说1234567891011public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; 当队列为空时，他会在notEmpty上进行等待，在线程等待时，若有新的元素插入，线程就会被唤醒12345678910private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; notEmpty.signal();&#125; 常用实现 SynchronousQueue(直接提交队列): 一个零容量队列，每个插入操作要对应一个删除操作。提交的任务不会被真实保存，其实就是将新任务交给了线程执行。 ArrayBlockingQueue(有界任务队列): 这里就会用到线程池中另一个参数maximumPoolSize, 若当前线程池中线程小于corePoolSize则直接在线程池中增加线程，若大于，则加入该任务队列，若队列满则继续加入线程池，若线程池中数目多余maximumPoolSize则执行拒绝策略。 LinkedBlockingQueue(无界任务队列)：如果未指定容量，那么容量将等于 Integer.MAX_VALUE。只要插入元素不会使双端队列超出容量，每次插入后都将动态地创建链接节点。 PriorityBlockingQueue(优先任务队列)： 一个特殊的无界任务队列，前面两者都是按FIFO的顺序执行，而这个是可以按照优先级执行。拒绝策略JDK内置拒绝策略如下 AboerPolicy(默认）：直接抛出异常，阻止系统正常工作。 CallerRunsPolicy: 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。（伪丢弃，但是任务提交线程性能大幅度下降） DiscardOledestPolicy:和名字一样，丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。 DiscardPolicy: 丢弃无法处理的任务，不给任何处理。 异常堆栈首先给出一个例子：123456789101112131415161718192021222324252627public class Main implements Runnable&#123; int a, b; public Main(int a, int b) &#123; this.a = a; this.b = b; &#125; @Override public void run() &#123; int ret = a / b; System.out.println(ret); &#125; public static void main(String[] args) &#123; ThreadPoolExecutor pools = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 0L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); for (int i = 0; i &lt; 5; i++) &#123; pools.submit(new Main(100, i)); &#125; &#125;&#125;/* 结果如下100335025*/ 可以发现，其中一个显然的异常除数为0不见了，我们可以通过将submit方法改为execute方法来打印部分异常信息，但是我们仍然不能发现他的调用线程在哪儿。这里我们通过扩展线程池给出一种解决办法。1234567891011121314151617181920212223242526272829303132333435363738394041424344package first_maven;import java.util.concurrent.BlockingQueue;import java.util.concurrent.Future;import java.util.concurrent.SynchronousQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Main extends ThreadPoolExecutor&#123; public Main(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); &#125; @Override public void execute(Runnable task) &#123; super.execute(wrap(task, clientTrace(), Thread.currentThread().getName())); &#125; @Override public Future&lt;?&gt; submit(Runnable task) &#123; return super.submit(wrap(task, clientTrace(), Thread.currentThread().getName())); &#125; private Exception clientTrace() &#123; return new Exception("Client stack trace"); &#125; private Runnable wrap(final Runnable task, final Exception clientStack, String clientThreadName) &#123; return new Runnable() &#123; @Override public void run() &#123; try &#123; task.run(); &#125; catch(Exception e) &#123; clientStack.printStackTrace(); System.out.println(" 1212"); throw e; &#125; &#125; &#125;; &#125;&#125; 我们通过扩展ThreadPoolExecutor，将要执行的Runnable进行包装，通过手动创建异常，获取当前主线程的调用堆栈，从而得到线程池的调用信息，并打印相应的运行异常，这样我们就可以追踪到完整的异常信息。 总结在使用多线程的时候，要通过ThreadPoolExecutor来手动创建，根据当前任务的需求分配相应的线程池大小和阻塞队列以及拒绝策略，这样才能知根知底。 五. References 《实战Java高并发程序设计》 《阿里巴巴Java开发手册》]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工厂模式]]></title>
    <url>%2F2018%2F01%2F13%2F%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[这两天正在看关于多线程的一些内容，看到线程池的时候发现它的实现使用了工厂模式，之前对工厂模式的了解不深，只是知道他是根据需要创建对象的，索性就开个支线，找了本书看了看关于工厂模式的一些知识，书中讲的也比较有意思，以下是一些心得。 概述对于设计模式来说，模式本身固然重要，但是模式设计的思想也同样很有味道，其中带来的一些OO的原则更是我们平时写代码需要注意的地方。而对于OO的设计原则其中有一个重要的思想就是将固定与变化分开，也就是简单的策略模式，将变化抽象，针对同一个接口，有各自的实现。 但是对于创建对象来说，java中只有new这一种方法，这就不可避免的要将代码写死，这又是我们不想看到的事情，由于硬编码带来的一系列拓展上的不便，使我们无法针对接口编程。就好像当我们使用集合的使用都会这么写： 1List&lt;T&gt; list = new XXXList&lt;&gt;(); 因为这种针对接口的编程给了我们更多的自由。那么有没有一种灵活的方式创建对象，那就是工厂模式，所有的工厂模式都是针对对象的创建。 一.简单工厂首先声明一下，简单工厂不是一种设计模式，只是一种习惯而已。他将动态的创建对象这一过程与固定的使用对象的代码分隔开。我们结合一个简单的例子来说：1234567891011121314151617181920212223242526272829303132333435363738394041class PizzaStore &#123; SimplePizzaFactory factory; public PizzaStore(SimplePizzaFactory factory) &#123; this.factory = factory; &#125; public Pizza orderPizza(String type) &#123; Pizza pizza; pizza = factory.createPizza(type); pizza.prepare(); pizza.bake(); pizza.cut(); pizza.box(); return pizza; &#125;&#125;public class SimplePizzaFactory &#123; public Pizza createPizza(String type) &#123; Pizza pizza = null; if (type.equals("cheese")) &#123; pizza = new CheesePizza(); &#125; else if (type.equals("pepperoni")) &#123; pizza = new PepperoniPizza(); &#125; else if (type.equals("clam")) &#123; pizza = new ClamPizza(); &#125; else if (type.equals("veggie")) &#123; pizza = new VeggiePizza(); &#125; return pizza; &#125;&#125; 在这个例子中，我们所需要创建的对象是Pizza，但在这里我们通过一个factory代替了以往的new关键字来创建对象，而这样的好处也是显而易见的，在这个服务中，变化的是Pizza的种类，而处理Pizza 的流程是固定的。我们只需根据需要传入所需的factory，就能实现创建对象与使用对象的解耦。 我们通过定义一个工厂类，将创建对象的操作通过这个类来进行，当对象种类增加时，我们只需要修改工厂类，就是所谓类对修改关闭，对扩展开放。二. 工厂方法在上一个例子中，我们在PizzaStore中创建简单工厂对象，通过简单工厂创建对象，这不免让代码失去了一点弹性，让我们进一步抽象，将创建对象的方法进一步封装，形成一个抽象基类，让每个子类去各自实现自己所需的创建对象的方法。提高代码的可扩展性。下面给出例子：12345678910111213141516171819202122232425262728abstract class PizzaStore &#123; abstract Pizza createPizza(String item); public Pizza orderPizza(String type) &#123; Pizza pizza = createPizza(type); System.out.println("--- Making a " + pizza.getName() + " ---"); pizza.prepare(); pizza.bake(); pizza.cut(); pizza.box(); return pizza; &#125;&#125;public class ChicagoPizzaStore extends PizzaStore &#123; Pizza createPizza(String item) &#123; if (item.equals("cheese")) &#123; return new ChicagoStyleCheesePizza(); &#125; else if (item.equals("veggie")) &#123; return new ChicagoStyleVeggiePizza(); &#125; else if (item.equals("clam")) &#123; return new ChicagoStyleClamPizza(); &#125; else if (item.equals("pepperoni")) &#123; return new ChicagoStylePepperoniPizza(); &#125; else return null; &#125;&#125; 在上面的代码中，对象的创建只给出了一个抽象方法，而具体的实现，则有子类自由选择决定，这样极大的丰富了代码的选择性和扩展性。基类实际上并不知道他持有的是什么对象，他主要负责持有对象后的一系列固定流程操作。 定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类把实例化推迟到子类。 对比工厂方法和简单工厂原本有一个对象负责所有具体类的实例化，而在工厂方法中则由一些子类来负责实例化。工厂方法用来处理对象的创建，并将行为封装在子类，这样基类的代码就和子类的对象创建完全解耦。 三. 抽象工厂当你需要创建的对象也依赖了一系列可变对象，那么就需要工厂模式中的最后一种方式–抽象工厂。我们首先给出抽象工厂的定义： 提供一个借口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。让我们再用Pizza来举例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ChicagoPizzaStore extends PizzaStore &#123; protected Pizza createPizza(String item) &#123; Pizza pizza = null; PizzaIngredientFactory ingredientFactory = new ChicagoPizzaIngredientFactory(); if (item.equals("cheese")) &#123; pizza = new CheesePizza(ingredientFactory); pizza.setName("Chicago Style Cheese Pizza"); &#125; else if (item.equals("veggie")) &#123; pizza = new VeggiePizza(ingredientFactory); pizza.setName("Chicago Style Veggie Pizza"); &#125; else if (item.equals("clam")) &#123; pizza = new ClamPizza(ingredientFactory); pizza.setName("Chicago Style Clam Pizza"); &#125; else if (item.equals("pepperoni")) &#123; pizza = new PepperoniPizza(ingredientFactory); pizza.setName("Chicago Style Pepperoni Pizza"); &#125; return pizza; &#125;&#125;class ChicagoPizzaIngredientFactory implements PizzaIngredientFactory &#123; public Dough createDough() &#123; return new ThickCrustDough(); &#125; public Sauce createSauce() &#123; return new PlumTomatoSauce(); &#125; public Cheese createCheese() &#123; return new MozzarellaCheese(); &#125; public Veggies[] createVeggies() &#123; Veggies veggies[] = &#123; new BlackOlives(), new Spinach(), new Eggplant() &#125;; return veggies; &#125; public Pepperoni createPepperoni() &#123; return new SlicedPepperoni(); &#125; public Clams createClam() &#123; return new FrozenClams(); &#125;&#125; PizzaStore和之前一样，这里就不重复了，和之前不一样的是在子类的createPizza方法中，我们不是简单的返回对象，而是根据创建对象所依赖的成员的不同，也进行了“个性化定制”。 其本质上其实也是用工厂方法对依赖对象进行创建。四. 抽象工厂与抽象方法的比较 工厂方法使用继承，把对象的创建委托给子类，子类实现工厂方法来创建对象，并将实例化延迟到子类。 抽象工厂使用组合，对象的创建被实现在工厂接口所暴露出来的方法中。 抽象工厂创建相关的对象家族，并让他们集合起来，而不需要依赖他们的具体类 五. References 《Head First 设计模式》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>工厂</tag>
        <tag>OO</tag>
      </tags>
  </entry>
</search>
